{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Rb9bicvVqke"
   },
   "source": [
    "##Â Run me on colab \n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/rjlopez2/ADS_CAS_Bern_2020/blob/main/Projects/M1%20and%20M2/M1M2_cas_project.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZNcjDy0ip5Qd"
   },
   "source": [
    "### **Import libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "id": "-5JnbT3Vp5Qf",
    "outputId": "0fec9e91-8337-4dc9-f4c6-3a19657e4f66"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "!pip install wget # uncomment this igf you run it via colab\n",
    "import os\n",
    "from zipfile import ZipFile\n",
    "import numpy as np\n",
    "import wget\n",
    "import fnmatch\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.max_rows', 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xukyw79xp5Qn"
   },
   "source": [
    "# Part I \n",
    "# M1 project \n",
    "\n",
    "## On data aquisition, formating and cleaning\n",
    "\n",
    "# 1. John Hopkins data collection and cleaning\n",
    "### **Download the time series datasets on global Covid cases from the John Hpkins University**\n",
    "The time series are organized in 3 different files from their Github repository:\n",
    "\n",
    " - one file retrieve information on the confirmed cases\n",
    " - one file retrieve information on the death cases\n",
    " - one file retrieve information on the recovered cases\n",
    "\n",
    "Below we download the 3 datastes and store them locally in .csv format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LgTaKV73p5Qs"
   },
   "outputs": [],
   "source": [
    "urls = ['https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv',\n",
    "       'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv',\n",
    "       'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_recovered_global.csv']\n",
    "\n",
    "path = os.getcwd() # get the current directory\n",
    "\n",
    "for url in urls:\n",
    "    filename = path + '/' + os.path.basename(url) # get the full path of the file\n",
    "    if os.path.exists(filename):\n",
    "        os.remove(filename) # if exist, remove it directly\n",
    "    wget.download(url, out=filename) # download it to the specific path.\n",
    "    \n",
    "# IMPORTANT: if error loading files bacause link is down, don't run this code chunk and go to the next.\n",
    "# It will read only the local data in the repo from the last time this script was run and updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cgp4WyBrp5Qy"
   },
   "outputs": [],
   "source": [
    "confirmed_df = pd.read_csv('time_series_covid19_confirmed_global.csv')\n",
    "deaths_df = pd.read_csv('time_series_covid19_deaths_global.csv')\n",
    "recovered_df = pd.read_csv('time_series_covid19_recovered_global.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ijRSVaN39LGj"
   },
   "source": [
    "### **We explore below the structure of the 3 datasets**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U8XajHkl9LGn"
   },
   "source": [
    "By looking at the shape of the 3 df, we observe that the recovered_df has different dimention than the two others.\n",
    "Closer inspection revealed that 14 provinces from Canada were missed in the recovered_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "34Lmqyj-p5Q3",
    "outputId": "2f614df6-e89e-4e52-9880-3daacf31815d"
   },
   "outputs": [],
   "source": [
    "# check size of the 3 datasets\n",
    "print([confirmed_df.shape, deaths_df.shape, recovered_df.shape])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 483
    },
    "id": "oiH9wwle9LHB",
    "outputId": "c1aa6474-e3ef-42f0-ecc4-63c9142a34d2"
   },
   "outputs": [],
   "source": [
    "confirmed_df[~confirmed_df['Province/State'].isin(recovered_df['Province/State'])][['Province/State', 'Country/Region']] # !!! 14 'Province/State'  no found in the recovered_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CkgwTgf-9LHO"
   },
   "source": [
    "Because of this inconsistency, we decided to exclude data from Canada for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HrN7gZkE9LHP"
   },
   "outputs": [],
   "source": [
    "recovered_df = recovered_df[recovered_df['Country/Region']!='Canada']\n",
    "confirmed_df = confirmed_df[confirmed_df['Country/Region']!='Canada']\n",
    "deaths_df = deaths_df[deaths_df['Country/Region']!='Canada']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "o8tLnEDv9LHb",
    "outputId": "6a2945c9-59bb-472c-b800-d79f5310fdc0"
   },
   "outputs": [],
   "source": [
    "# check size of the 3 datasets\n",
    "print([confirmed_df.shape, deaths_df.shape, recovered_df.shape])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wWy3EPy0p5RL"
   },
   "source": [
    "We observed that the first 4 colums of each dataset have the same variables so we use them to merge all 3 datasets and we define the time variable with the rest of the colums\n",
    "\n",
    "1. We create the vector for the time varibale\n",
    "2. we transform the 3 dataframes to long format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "id": "bhw2Bggyp5Q8",
    "outputId": "9eb313cc-a60b-4248-da75-ce7a214eea47"
   },
   "outputs": [],
   "source": [
    "recovered_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "id": "AQeP3ml9p5RB",
    "outputId": "c7a8bf1f-092f-4140-8fb2-04f9550a8f78"
   },
   "outputs": [],
   "source": [
    "deaths_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "id": "siq1uGeip5RF",
    "outputId": "74c91d03-0e06-4ca4-bf11-acf3cfc84941"
   },
   "outputs": [],
   "source": [
    "confirmed_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iDjFoRGip5RM"
   },
   "outputs": [],
   "source": [
    "dates = confirmed_df.columns[4:]\n",
    "\n",
    "confirmed_df_long = confirmed_df.melt(\n",
    "    id_vars=['Province/State', 'Country/Region', 'Lat', 'Long'], \n",
    "    value_vars=dates, \n",
    "    var_name='Date', \n",
    "    value_name='Confirmed')\n",
    "\n",
    "deaths_df_long = deaths_df.melt(\n",
    "    id_vars=['Province/State', 'Country/Region', 'Lat', 'Long'], \n",
    "    value_vars=dates, \n",
    "    var_name='Date', \n",
    "    value_name='Deaths')\n",
    "\n",
    "recovered_df_long = recovered_df.melt(\n",
    "    id_vars=['Province/State', 'Country/Region', 'Lat', 'Long'], \n",
    "    value_vars=dates, \n",
    "    var_name='Date', \n",
    "    value_name='Recovered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "la__bkXMVqmr",
    "outputId": "32669769-fea2-40f1-f854-4a5bbef3177f"
   },
   "outputs": [],
   "source": [
    "# check the size of each dataset in long format\n",
    "print([confirmed_df_long.shape, deaths_df_long.shape, recovered_df_long.shape])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "Qo2YWwNFVqmz",
    "outputId": "9d1d1170-eaff-4b97-9f45-d8da94522ed1"
   },
   "outputs": [],
   "source": [
    "# check if the number of countries are the same in each subset\n",
    "print(confirmed_df_long['Country/Region'].drop_duplicates().shape, \n",
    "      deaths_df_long['Country/Region'].drop_duplicates().shape, \n",
    "      recovered_df_long['Country/Region'].drop_duplicates().shape)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confirmed_df_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xThDNSz-p5Rd"
   },
   "outputs": [],
   "source": [
    "# Merge the 3 datasets \n",
    "\n",
    "confirmed_df_long[\"Deaths\"] = deaths_df_long[\"Deaths\"]\n",
    "confirmed_df_long[\"Recovered\"] = recovered_df_long['Recovered']\n",
    "full_table = confirmed_df_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "id": "Zw_0HvDrp5Rg",
    "outputId": "6e69751d-129b-4664-89b0-d6ad7fcb89f3"
   },
   "outputs": [],
   "source": [
    "full_table.info(verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S_6DV-4Ep5Rj"
   },
   "outputs": [],
   "source": [
    "# trasnform from string to date the \"Date\" column\n",
    "full_table['Date'] = pd.to_datetime(full_table['Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4jnEGs9Tp5Rm"
   },
   "source": [
    "### **Check and fix NaN in the full dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "id": "ZF9W8__Pp5Rm",
    "outputId": "fc1ffa13-e5c2-4b1b-ad65-1a3c136be042"
   },
   "outputs": [],
   "source": [
    "full_table.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cPz6eVHup5Rr"
   },
   "source": [
    "### **Remove cruise ships data**\n",
    " #### We also observed that there is some of confirmed cases of Covid from the cruise ships (Grand Princess, Diamond Princess and MS Zaandam) that make it difficult to fit in in the Country category, so we excluded from our anaysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hpMrI_Bqp5Rs"
   },
   "outputs": [],
   "source": [
    "# select the ships rows\n",
    "ship_rows = full_table['Province/State'].str.contains('Grand Princess') | full_table['Province/State'].str.contains('Diamond Princess') | full_table['Country/Region'].str.contains('Diamond Princess') | full_table['Country/Region'].str.contains('MS Zaandam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5GevP13Gp5R0"
   },
   "outputs": [],
   "source": [
    "full_table = full_table[~(ship_rows)] # the '~' operator negate the selections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bf3mSML5p5R5"
   },
   "source": [
    "## **Add new colum for active cases**\n",
    "Below we compute the active cases by substracting the number of death and recovered to the confirmed cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 541
    },
    "id": "j2Dk58s2p5R6",
    "outputId": "01440846-5b45-4baa-9699-09a85b445ff4"
   },
   "outputs": [],
   "source": [
    "# Active Case = confirmed - deaths - recovered\n",
    "full_table['Active'] = full_table['Confirmed'] - full_table['Deaths'] - full_table['Recovered']\n",
    "full_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-0GWyShBp5R8"
   },
   "source": [
    "We agregate the data by Country and Date (by means of grouping) and calculate de sum of the cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "y9ukj4knp5R9",
    "outputId": "111156d5-ee25-4561-8d8d-f36e0e38de99"
   },
   "outputs": [],
   "source": [
    "full_grouped = full_table.groupby(['Date', 'Country/Region'])[['Confirmed', 'Deaths', 'Recovered', 'Active']].sum().reset_index()\n",
    "\n",
    "full_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C1Y8V3Om9LKZ"
   },
   "source": [
    "## Add new column(s) for new cases / new deaths / new recovered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "id": "g6m1YPUo9LKb",
    "outputId": "e7e8ac7b-1a8d-49de-9144-863273981bee"
   },
   "outputs": [],
   "source": [
    "# new cases \n",
    "temp = full_grouped.groupby(['Country/Region', 'Date', ])['Confirmed', 'Deaths', 'Recovered']\n",
    "temp = temp.sum().diff().reset_index()\n",
    "\n",
    "mask = temp['Country/Region'] != temp['Country/Region'].shift(1)\n",
    "\n",
    "temp.loc[mask, 'Confirmed'] = np.nan\n",
    "temp.loc[mask, 'Deaths'] = np.nan\n",
    "temp.loc[mask, 'Recovered'] = np.nan\n",
    "\n",
    "# renaming columns\n",
    "temp.columns = ['Country/Region', 'Date', 'New_cases', 'New_deaths', 'New_recovered']\n",
    "\n",
    "# merging new values\n",
    "full_grouped = pd.merge(full_grouped, temp, on=['Country/Region', 'Date'])# filling na with 0\n",
    "full_grouped = full_grouped.fillna(0)\n",
    "\n",
    "# fixing data types\n",
    "cols = ['New_cases', 'New_deaths', 'New_recovered']\n",
    "full_grouped[cols] = full_grouped[cols].astype('int')\n",
    "\n",
    "# \n",
    "full_grouped['New_cases'] = full_grouped['New_cases'].apply(lambda x: 0 if x<0 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XHINTWYip5R_"
   },
   "outputs": [],
   "source": [
    "#rename the \"Country/Region\" variable\n",
    "full_grouped.rename(columns = {'Country/Region' : 'Country_Region'}, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "F4r3Ehz5p5SC",
    "outputId": "6283220f-419f-4e64-88be-0929377dae18"
   },
   "outputs": [],
   "source": [
    "# compute the number of countries registered in the covide dataset\n",
    "full_grouped['Country_Region'].unique().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_hbINcIq9LK9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MpL0eTgip5SE"
   },
   "source": [
    "## **Extract metadata for Covid datasets**\n",
    "We want to merge the covid dataset with other datasets by a comun variable, in our case is the Country. To make sure that the union of datasets are compatible, and since countries might be named disticntly  from each dataset source we use the country code as an standard varibale fro later merge. Now we asign to the Covid dataframe a new colum for the Country codes. To achieve this task we do the following steps: \n",
    " - Load metadata from the Covid repository\n",
    " - Extract the information on Country code (here is the variable called 'iso3')\n",
    "\n",
    "We also extract additional information on the population from each country. this will be used later for normalizing our variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EP8Qv_Jip5SF"
   },
   "outputs": [],
   "source": [
    "covid_metadata_countries = pd.read_csv(\"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/UID_ISO_FIPS_LookUp_Table.csv\",\n",
    "                                      usecols = ['Country_Region', 'Province_State', 'iso3', 'Population'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "r6Vp_haVp5SH",
    "outputId": "f17b46b5-1508-41ca-b14c-98fe9d11b788"
   },
   "outputs": [],
   "source": [
    "covid_metadata_countries.info(verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nHSFR3sqp5SI"
   },
   "source": [
    "### **Remove regional subset in hte metadata and only work at national level**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_metadata_countries = covid_metadata_countries[covid_metadata_countries['Province_State'].isna()].drop_duplicates()#.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nHSFR3sqp5SI"
   },
   "source": [
    "### **Remove the cruise ships information from the metadata on country codes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UCo1c7sjp5SL"
   },
   "outputs": [],
   "source": [
    "# select from columns 'Country_Region' the names 'Diamond Princess'and 'MS Zaandam'\n",
    "ship_metadata = covid_metadata_countries['Country_Region'].str.contains('Diamond Princess') | covid_metadata_countries['Country_Region'].str.contains('MS Zaandam')\n",
    "ship_metadata\n",
    "covid_metadata_countries = covid_metadata_countries[~(ship_metadata)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "43BRMBXqp5SN"
   },
   "source": [
    "### **Summarize the population by country in the metadata dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XosG0thQp5SO"
   },
   "outputs": [],
   "source": [
    "#my_covid_variables = ['Confirmed', 'Deaths', 'Recovered', 'Active']\n",
    "code_vars = ['Country_Region', 'iso3']\n",
    "\n",
    "#full_table.groupby(['Date', 'Country/Region'])[my_covid_variables].sum().reset_index()\n",
    "country_population = covid_metadata_countries.groupby(code_vars)['Population'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "4g79RRkDp5SQ",
    "outputId": "7a13ad90-7cb2-4149-a5ba-67320b55bc20"
   },
   "outputs": [],
   "source": [
    "country_population['Country_Region'].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "9RLB833C9LMY",
    "outputId": "ad6eb2fb-db7e-48ad-9f4f-f9cab7fa75fb"
   },
   "outputs": [],
   "source": [
    "# this is the number of countries registered in the Covid df\n",
    "full_grouped['Country_Region'].unique().size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "okjboLfEp5SX"
   },
   "source": [
    "### **Merge country code with Covid datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V10m-r0_p5SX"
   },
   "outputs": [],
   "source": [
    "full_grouped_ccode = pd.merge(country_population, full_grouped, how = 'left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "id": "xS5LjLIep5SY",
    "outputId": "c17c510c-9e12-4005-b516-23e16f38f095"
   },
   "outputs": [],
   "source": [
    "full_grouped_ccode.info(verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sCZAVRjop5Sb"
   },
   "outputs": [],
   "source": [
    "full_grouped_ccode.rename(columns = {'iso3' : 'CountryCode'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "id": "hsZg9qwsVqoz",
    "outputId": "e804ef73-c6db-4485-9c4d-871e3bcf19d0"
   },
   "outputs": [],
   "source": [
    "# Check NaNs generated during the merge and remove them\n",
    "full_grouped_ccode.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fm_e84b9Vqo5"
   },
   "outputs": [],
   "source": [
    "full_grouped_ccode = full_grouped_ccode[~full_grouped_ccode['Date'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ADIMImLp5Sf"
   },
   "source": [
    "# 2. Oxford Stringency index data collection, cleaning and merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OkSvCaZRVqpG"
   },
   "outputs": [],
   "source": [
    "str_url = [\"https://raw.githubusercontent.com/OxCGRT/covid-policy-tracker/master/data/OxCGRT_latest.csv\"]\n",
    "\n",
    "for url in str_url:\n",
    "    filename = path + '/' + os.path.basename(url) # get the full path of the file\n",
    "    if os.path.exists(filename):\n",
    "        os.remove(filename) # if exist, remove it directly\n",
    "    wget.download(url, out=filename) # download it to the specific path.\n",
    "# IMPORTANT: if error loading files bacause link is down, don't run this code chunk and go to the next.\n",
    "# It will read only the local data in the repo from the last time this script was run and updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "id": "yOmnWSkTp5Sf",
    "outputId": "4a5335f5-6870-4efe-e7da-89bcd7c6dbd8"
   },
   "outputs": [],
   "source": [
    "my_string_columns = [\"Date\", \"CountryCode\", \"CountryName\", \"StringencyIndex\", \"RegionName\", \"RegionCode\"] \n",
    "stringency_raw_dataset = pd.read_csv(\"OxCGRT_latest.csv\", usecols = my_string_columns, low_memory=False)\n",
    "stringency_raw_dataset.info(verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ubalw-rqp5Sg"
   },
   "source": [
    "### **Selecting national data only ( exclude regional data) read documentation in this link why -> https://github.com/OxCGRT/covid-policy-tracker**\n",
    "To take only the natinal data we followed instructions in the link above and take only rows where the variable RegionCoide is Null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YLNub_hsp5Sh"
   },
   "outputs": [],
   "source": [
    "stringe_natio_dataset = stringency_raw_dataset[stringency_raw_dataset.RegionCode.isnull()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "egxYenh1p5Sl"
   },
   "outputs": [],
   "source": [
    "# remove columns with no needed information\n",
    "stringe_natio_dataset = stringe_natio_dataset[my_string_columns[:4]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AbDu_6PE9LNx"
   },
   "source": [
    "Closer inspection revealed that the number of country codes from the Stringency dataset is less than the number of country codes in the Covid dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "xFbmKuf_p5So",
    "outputId": "472cd213-7489-4f4f-93f1-1934c49edb23"
   },
   "outputs": [],
   "source": [
    "print([stringe_natio_dataset['CountryCode'].unique().size, \n",
    "       full_grouped_ccode['CountryCode'].unique().size])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K4EL7iZfp5Ss"
   },
   "source": [
    "#### **The list below shows the Countries/region/dependencies which have not information regarding stringency index. Those countries (31) will be excluded form the analysis for the momment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "DOqYxex5p5Ss",
    "outputId": "fa3800b9-fb09-451e-cc25-1b54856e815f"
   },
   "outputs": [],
   "source": [
    "# finding What is not present in the stringency dataset\n",
    "full_grouped_ccode[~full_grouped_ccode['CountryCode'].isin(stringe_natio_dataset['CountryCode'])][['CountryCode', 'Country_Region']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0rSdS7SJp5S3"
   },
   "outputs": [],
   "source": [
    "## We filtered out the countries above for joining with the covid dataset\n",
    "full_grouped_ccode_filtered = full_grouped_ccode[full_grouped_ccode['CountryCode'].isin(stringe_natio_dataset['CountryCode'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "id": "Z-Z9fvhDp5S6",
    "outputId": "6539175b-b46f-4686-9036-5d445534b8cc"
   },
   "outputs": [],
   "source": [
    "full_grouped_ccode_filtered.info(verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "elyc89vwp5S7"
   },
   "source": [
    "### Fixing the date format in the stringency dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_ztEKtK_p5S8"
   },
   "outputs": [],
   "source": [
    "#stringency_raw_dataset.info(verbose = True)\n",
    "stringe_natio_dataset['Date'] = pd.to_datetime(stringe_natio_dataset['Date'], format = '%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "HuwY5_Rvp5S-",
    "outputId": "fbe338f0-15b0-4a6e-f5af-53bf75eefc68"
   },
   "outputs": [],
   "source": [
    "stringe_natio_dataset.info(verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "NhYeL4gcVqqX",
    "outputId": "51e7b8bd-0066-4087-c733-8338914a07fd"
   },
   "outputs": [],
   "source": [
    "stringe_natio_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rzokZI-DVqqg"
   },
   "source": [
    "### Create categories for Stringency index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "rst1alssVqqh",
    "outputId": "8ab5698f-6427-4985-c605-a3801df44f11"
   },
   "outputs": [],
   "source": [
    "condition1 = (stringe_natio_dataset[\"StringencyIndex\"] >= 0) & (stringe_natio_dataset[\"StringencyIndex\"] <= 20)\n",
    "condition2 = (stringe_natio_dataset[\"StringencyIndex\"] > 20) & (stringe_natio_dataset[\"StringencyIndex\"] <= 40)\n",
    "condition3 = (stringe_natio_dataset[\"StringencyIndex\"] > 40) & (stringe_natio_dataset[\"StringencyIndex\"] <= 60)\n",
    "condition4 = (stringe_natio_dataset[\"StringencyIndex\"] > 60) & (stringe_natio_dataset[\"StringencyIndex\"] <= 80)\n",
    "condition5 = (stringe_natio_dataset[\"StringencyIndex\"] > 80) & (stringe_natio_dataset[\"StringencyIndex\"] <= 100)\n",
    "\n",
    "case1 = \"Very_low\"\n",
    "case2 = \"Low\"\n",
    "case3 = \"Middle\"\n",
    "case4 = \"High\"\n",
    "case5 = \"Very_high\"\n",
    "\n",
    "\n",
    "stringe_natio_dataset[\"StringencyIndex_factor\"] = np.where(condition1, case1, \n",
    "                                                    np.where(condition2, case2, \n",
    "                                                            np.where(condition3, case3,\n",
    "                                                                    np.where(condition3, case3,\n",
    "                                                                            np.where(condition4, case4,\n",
    "                                                                                    np.where(condition5, case5,\n",
    "                                                                                            \"unknown\"))))))\n",
    "stringe_natio_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AlrhZGj5p5TB"
   },
   "source": [
    "# 3. Joining Covid cases with Stringency index data \n",
    "Join the covid dataset with the stringency dataset and transfrm the final df in a timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "lwrWcwsMp5TG",
    "outputId": "13337d29-c105-4c79-8ccd-92118ff882c7"
   },
   "outputs": [],
   "source": [
    "my_complete_df = pd.merge(stringe_natio_dataset[['Date', 'CountryCode','StringencyIndex', 'StringencyIndex_factor']], # selecting only the variables to join\n",
    "                          full_grouped_ccode_filtered)\n",
    "\n",
    "my_complete_df.info(verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gpWNCGu_p5TL"
   },
   "outputs": [],
   "source": [
    "my_complete_df.set_index('Date', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 640
    },
    "id": "WyIZkmEY9LPH",
    "outputId": "746d8f08-6911-425f-c20d-a811bda85bca"
   },
   "outputs": [],
   "source": [
    "my_complete_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kzVZMFdw9LPP"
   },
   "source": [
    "## Normalize the variables on all cases by 100.000 people per country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 640
    },
    "id": "oFt_DnX29LPh",
    "outputId": "3d049820-406c-4fbb-dcc0-bee780bd9cb7"
   },
   "outputs": [],
   "source": [
    "my_complete_df['Confirmed_100K'] = my_complete_df['Confirmed'].multiply(100000, fill_value = 0).divide(my_complete_df['Population'], fill_value = 0)\n",
    "my_complete_df['Deaths_100K'] = my_complete_df['Deaths'].multiply(100000, fill_value = 0).divide(my_complete_df['Population'], fill_value = 0)\n",
    "my_complete_df['Recovered_100K'] = my_complete_df['Recovered'].multiply(100000, fill_value = 0).divide(my_complete_df['Population'], fill_value = 0)\n",
    "my_complete_df['Active_100K'] = my_complete_df['Active'].multiply(100000, fill_value = 0).divide(my_complete_df['Population'], fill_value = 0)\n",
    "my_complete_df['New_cases_100K'] = my_complete_df['New_cases'].multiply(100000, fill_value = 0).divide(my_complete_df['Population'], fill_value = 0)\n",
    "my_complete_df['New_deaths_100K'] = my_complete_df['New_deaths'].multiply(100000, fill_value = 0).divide(my_complete_df['Population'], fill_value = 0)\n",
    "my_complete_df['New_recovered_100K'] = my_complete_df['New_recovered'].multiply(100000, fill_value = 0).divide(my_complete_df['Population'], fill_value = 0)\n",
    "my_complete_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5oCBPzSd9LPr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "39RaU7Iq9LP1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uf2QcMJR9LQE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kPcEZsSZ9LQR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sIJoXNEAVqrr"
   },
   "source": [
    "# NOTE: This old visualization chunk section below can be removed and use the new one you have created in the exploratory analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4qmgYacLp5TO"
   },
   "source": [
    "## Visualizing Covid data by individual countries\n",
    "To visualize a country performance with the Covid assign a country code to the variable my_country from the following diccionary of countries names and codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R0jomGJY9LQY"
   },
   "outputs": [],
   "source": [
    "my_countries_dicc = my_complete_df[['CountryCode', 'Country_Region']].drop_duplicates().reset_index()[['CountryCode', 'Country_Region']].set_index('CountryCode').to_dict()['Country_Region']\n",
    "\n",
    "#my_countries_dicc# to see al country codes and names uncomment this line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VJvKbMqF9LQd"
   },
   "source": [
    "Here we take an example visualizing the dataset from Switzerland (CHE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 640
    },
    "id": "h5Aze5Cq9LQe",
    "outputId": "38205cba-aff0-4935-def8-ab8f755c2460"
   },
   "outputs": [],
   "source": [
    "country = 'CHN'\n",
    "single_country_covid_df = my_complete_df[my_complete_df['CountryCode'] == country]\n",
    "single_country_covid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PHjqxmCu9LQm"
   },
   "outputs": [],
   "source": [
    "# my_vars_for_ploting = ['StringencyIndex', 'New_cases_100K', 'New_deaths_100K', 'New_recovered_100K', 'Confirmed_100K', 'Deaths_100K', 'Recovered_100K', 'Active_100K']\n",
    "\n",
    "# i = 0\n",
    "# for variables in range(len(my_vars_for_ploting)):\n",
    "#     single_country_covid_df.plot(y=my_vars_for_ploting[i],\n",
    "#                                  kind=\"line\",\n",
    "# #                                  c=['c', 'b'], \n",
    "#                                  c = 'c',\n",
    "#                                  label = my_vars_for_ploting[i]) # = ['StringencyIndex', 'New cases', 'New deaths', 'New recovered', 'Confirmed', 'Deaths', 'Recovered']])\n",
    "#     plt.title('Country = ' + my_countries_dicc['Country_Region'][country])\n",
    "#     i+=1\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l8qDH34Xp5TX"
   },
   "source": [
    "# 4. Colecting and merging Socieconomical data from the WorldBank\n",
    "We extract socieconomical data such is GDP and Income level from the Worldbank datasets via API query request protocol.\n",
    "\n",
    "**Note**: retrieving *GDP* and *income level* doesn't seem to be so straightforward in a single call. So may be the strategy would be to make a call for each dataset and then merge then."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fSHR4rF6Vqr-"
   },
   "outputs": [],
   "source": [
    "my_home_url = 'http://api.worldbank.org/v2/country/all/indicator/NY.GDP.MKTP.CD'\n",
    "my_params = {'date' : '2019',\n",
    "            'incomelevel' :'',\n",
    "            'downloadformat' : 'csv',\n",
    "            'per_page' : '304'} # dic with the parameters of interest\n",
    "\n",
    "\n",
    "# remove excel file if exists\n",
    "for file in os.listdir(path):\n",
    "    if fnmatch.fnmatch(file, 'API_*.csv'):\n",
    "        os.remove(file)\n",
    "\n",
    "# remove excel file if exists\n",
    "for file in os.listdir(path):\n",
    "    if fnmatch.fnmatch(file, 'Metadata_*.csv'):\n",
    "        os.remove(file)\n",
    "        \n",
    "        \n",
    "        \n",
    "# if the zip file exist it will be updated\n",
    "for file in os.listdir(path):\n",
    "    if fnmatch.fnmatch(file, '*.zip'):\n",
    "        file_exists = True\n",
    "        os.remove(file)\n",
    "        r_GDP = requests.get(my_home_url, params = my_params)\n",
    "        my_zip_file = wget.download(r_GDP.url)\n",
    "        \n",
    "#         for i in list_files:\n",
    "#             os.remove(file)\n",
    "#             r_GDP = requests.get(my_home_url, params = my_params)\n",
    "#             my_zip_file = wget.download(r_GDP.url)\n",
    "\n",
    "    else:\n",
    "        file_exists = False\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the zip file doesent exist it will be downloaded\n",
    "if file_exists == False:\n",
    "    r_GDP = requests.get(my_home_url, params = my_params)\n",
    "    my_zip_file = wget.download(r_GDP.url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(path):\n",
    "    if fnmatch.fnmatch(file, '*.zip'):\n",
    "        #print(file)# find only the zip file\n",
    "        with ZipFile(file, 'r') as zipObj:\n",
    "            for content in zipObj.namelist():\n",
    "                if fnmatch.fnmatch(content, 'API_*'):\n",
    "                    #print(content) wihtin the content of the zip file find and extract the csv file that contain the data\n",
    "                    my_filename = content\n",
    "                    zipObj.extract(content)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "QGtrutM1p5TX",
    "outputId": "a8bbb207-7261-4661-a2e5-863185651dd0"
   },
   "outputs": [],
   "source": [
    "GDP_raw_df = pd.read_csv(path + '/' + my_filename,\n",
    "                        header = 2,\n",
    "                        usecols = [1, 4])\n",
    "GDP_raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "id": "AnwLXoXyp5TZ",
    "outputId": "cb6c2eec-aae1-4f50-8427-7d13845964a7"
   },
   "outputs": [],
   "source": [
    "GDP_raw_df.info(verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "BqvPpijr9LQ_",
    "outputId": "dffc3b23-f621-447c-901d-ec9caba7e9c4"
   },
   "outputs": [],
   "source": [
    "# 1. fixing names in GDP_raw_df dataset\n",
    "\n",
    "GDP_correct_names = {'Country Code' : 'CountryCode',\n",
    "                     '2019' : 'GDP_in_USD'}\n",
    "GDP_raw_df.rename(columns = GDP_correct_names, inplace= True)\n",
    "GDP_raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "qUoIc-Ri9LRG",
    "outputId": "ce9dbd53-274f-4757-bce1-efb500b4880b"
   },
   "outputs": [],
   "source": [
    "GDP_raw_df[~GDP_raw_df['CountryCode'].isin(my_complete_df['CountryCode'])].drop_duplicates().shape #this are the 88 regions or dependencies from the GDP dataset that are not in the Covid df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "dQ7cLINn9LRO",
    "outputId": "85db1659-735c-43cd-a4e2-083e96cf9b6c"
   },
   "outputs": [],
   "source": [
    "my_complete_df[my_complete_df['CountryCode'].isin(GDP_raw_df['CountryCode'])][['CountryCode']].drop_duplicates().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TxG7JZ7K9LRU"
   },
   "source": [
    "We select only those countries from the GDP df that are present in the covid dataframe to be merged with the covid full dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "id": "4Rx0Lkvu9LRV",
    "outputId": "2fa8e117-e05a-48d6-ce1e-b17382a28720"
   },
   "outputs": [],
   "source": [
    "GDP_raw_df = GDP_raw_df[GDP_raw_df['CountryCode'].isin(my_complete_df['CountryCode'])]\n",
    "GDP_raw_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YmlaUF3O9LRc"
   },
   "source": [
    "### Join the GDP data to the covid df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "id": "INkwkEn99LRd",
    "outputId": "3548a068-0ffd-4003-e9c5-3db7635762bf"
   },
   "outputs": [],
   "source": [
    "my_complete_df = my_complete_df.reset_index().merge(right=GDP_raw_df[['CountryCode', 'GDP_in_USD']],how='left', on=['CountryCode']).set_index('Date')\n",
    "my_complete_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "26DOwcZI9LRk"
   },
   "source": [
    "## We now extract data on Income level of the different countries from metadata files from the WorldBank in the zip file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(path):\n",
    "    if fnmatch.fnmatch(file, '*.zip'):\n",
    "        #print(file)# find only the zip file\n",
    "        with ZipFile(file, 'r') as zipObj:\n",
    "            for content in zipObj.namelist():\n",
    "                if fnmatch.fnmatch(content, 'Metadata_Country*'):\n",
    "                    #print(content) wihtin the content of the zip file find and extract the csv file that contain the data\n",
    "                    my_filename = content\n",
    "                    zipObj.extract(content)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "BcLAbqklVqs6",
    "outputId": "23b0a7f3-59a6-4fae-a539-0c40276e8070"
   },
   "outputs": [],
   "source": [
    "income_raw_df = pd.read_csv(my_filename,\n",
    "                        #header = 2,\n",
    "                        usecols = [0, 1, 2, 4])\n",
    "\n",
    "income_raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "esyfeEMn9LRs",
    "outputId": "57afa620-72cb-4884-b8f0-ce7da45e5ab4"
   },
   "outputs": [],
   "source": [
    "#2 (on income_raw_df)\n",
    "# make consistennt names for all datasets\n",
    "# 1. fixing names in income_raw_df dataset\n",
    "# 2. take only relevant columns\n",
    "\n",
    "income_correct_names = {'Country Code' : 'CountryCode',\n",
    "                        'TableName' : 'Country_Region'}\n",
    "\n",
    "income_raw_df.rename(columns = income_correct_names, inplace = True)\n",
    "income_raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "qWQxwM7t9LR7",
    "outputId": "eb4569cb-cf00-4242-8757-c32be51a6d78"
   },
   "outputs": [],
   "source": [
    "income_raw_df[~income_raw_df['CountryCode'].isin(my_complete_df['CountryCode'])].shape #this are the 85 regions or aggregated regions, dependencies from the income level dataset that are not in the Covid df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "B9vPW8sx9LSJ",
    "outputId": "8b0a3b3e-bb26-4ae9-f8de-98f6a10bb659"
   },
   "outputs": [],
   "source": [
    "my_complete_df[~my_complete_df['CountryCode'].isin(income_raw_df['CountryCode'])][['CountryCode']].drop_duplicates()#.shape # these 4 dependencies from de covid dataset have no income level information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bJZ0SE9G9LSY"
   },
   "source": [
    "### As before, we select only those countries from the Income level dataset wich are also present in the covid dataset, and exclude all other regions dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "GhM5jhTR9LSc",
    "outputId": "fb3faeb5-0094-4ac5-cc66-8732ee3f6d5c"
   },
   "outputs": [],
   "source": [
    "income_raw_df = income_raw_df[income_raw_df['CountryCode'].isin(my_complete_df['CountryCode'])]\n",
    "income_raw_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "524M-Nq99LSj"
   },
   "source": [
    "## We make the final join of the income level data with the covid dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 493
    },
    "id": "3sIK_TXU9LSm",
    "outputId": "9ffe28d5-a108-4e74-be91-3152224f360c"
   },
   "outputs": [],
   "source": [
    "my_final_df = my_complete_df.reset_index().merge(right=income_raw_df[['CountryCode', 'IncomeGroup']],how='left', on=['CountryCode']).set_index('Date')\n",
    "my_final_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 580
    },
    "id": "cXmx60ti9LSy",
    "outputId": "046ea3f3-91ec-4b92-82c4-02eee14457d6"
   },
   "outputs": [],
   "source": [
    "my_final_df.head(10)#[my_final_df['CountryCode'] == \"DEU\"][['New_deaths']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "id": "kexXH0qJVqte",
    "outputId": "c964d69c-a278-49a2-d6cd-d66cdf997cf7"
   },
   "outputs": [],
   "source": [
    "my_final_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cVoaEK899LSv"
   },
   "source": [
    "## This is the final clean working dataframe  which contain:\n",
    " - time series of Covid cases of 180 countries or dependencies etc from the world.\n",
    " - standard country code for ease finding of countries\n",
    " - the cumulative sum of confirmed, deatch and recovered cases\n",
    " - the new cases, new death and new recovered in a day-wise format\n",
    " - all varibales before mentioned normalized by 100.000 people per country. This is may be usefull to compare among different countries\n",
    " - government response on restraining the spread of the pandemic indicated by the restringency index\n",
    " - two socioeconomical indicators for countries: GDP in USD and Income level\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MhWkTt2w9LS9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iCvQm0yJ9LTO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u51M-kbF9LTY"
   },
   "source": [
    "# Part II \n",
    "# M2 project on descriptive statistics\n",
    "\n",
    "## 1.  Descriptive Statistics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "54iNUbRnZpzH"
   },
   "source": [
    "# 1. Visualization of Coronavirus cases per country and exploring which income group they belong to\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lu17N3wXd87T"
   },
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import spearmanr\n",
    "model = LinearRegression()\n",
    "import seaborn as sb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x6okGuHAYCqI"
   },
   "source": [
    "## Sorting the countries with the **hihgest** coronavirus outbreak\n",
    "We first sort the data to understand the countries with most cases\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "feeY0mPLfDvV"
   },
   "source": [
    "## Plotting the top ten MORE affected countries based on total tols and infecctions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "061yO2aF-Hr4",
    "outputId": "7ee33150-d742-4ee2-b915-9e62a3e01e76"
   },
   "outputs": [],
   "source": [
    "#find last reported date\n",
    "last_reported_date = my_final_df.reset_index().tail(1)['Date'].to_string(index = False)\n",
    "last_reported_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PbT1QbOJdMD0"
   },
   "outputs": [],
   "source": [
    "#find top 10 countries wiht highest numebr of deaths and confirmed cases (cumulative)\n",
    "my_top = 5\n",
    "top_deaths_100K = my_final_df.loc[last_reported_date].sort_values(by = \"Deaths_100K\", ascending = False).head(my_top).reset_index()['CountryCode'].to_list()#.set_index('CountryCode').to_dict()[\"Country_Region\"]\n",
    "top_confirmed_100K = my_final_df.loc[last_reported_date].sort_values(by = \"Confirmed_100K\", ascending = False).head(my_top).reset_index()['CountryCode'].to_list()#.set_index('CountryCode').to_dict()[\"Country_Region\"]\n",
    "\n",
    "top_deaths_100K_df = my_final_df[my_final_df['CountryCode'].isin(top_deaths_100K)].reset_index()\n",
    "top_confirmed_100K_df = my_final_df[my_final_df['CountryCode'].isin(top_confirmed_100K)].reset_index()\n",
    "\n",
    "# font = {'family' : 'normal',\n",
    "#         'weight' : 'bold',\n",
    "#         'size'   : 18}\n",
    "# plt.rc('font', **font)\n",
    "\n",
    "factor_size = 1.5\n",
    "SMALL_SIZE = 8 * factor_size\n",
    "MEDIUM_SIZE = 10 * factor_size\n",
    "BIGGER_SIZE = 12 * factor_size\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=BIGGER_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    "# Multiline Plot: number of confirmed cases in 100K \n",
    "fig1 = plt.figure(figsize=(22, 10) , dpi=300)\n",
    "\n",
    "\n",
    "ax1 = fig1.add_subplot(221)\n",
    "sb.lineplot(\n",
    "    data=top_confirmed_100K_df, \n",
    "#     kind=\"line\",\n",
    "    x=\"Date\", \n",
    "    y=\"Confirmed_100K\",\n",
    "    ax = ax1,\n",
    "    linewidth = 4,\n",
    "    hue=\"Country_Region\")\n",
    "plt.xticks(rotation=45) \n",
    "plt.legend(frameon=False)\n",
    "plt.legend(bbox_to_anchor=(1.04,1), borderaxespad=0)\n",
    "#plt.title('My title')\n",
    "\n",
    "ax2 = fig1.add_subplot(222)\n",
    "sb.barplot(\n",
    "    data=top_confirmed_100K_df[top_confirmed_100K_df['Date'] == last_reported_date], \n",
    "    x=\"IncomeGroup\", \n",
    "    y=\"Confirmed_100K\",\n",
    "    ax = ax2,\n",
    "    hue=\"Country_Region\")\n",
    "\n",
    "plt.legend(frameon=False)\n",
    "plt.legend(bbox_to_anchor=(1.04,1), borderaxespad=0)\n",
    "ax3 = fig1.add_subplot(223)\n",
    "\n",
    "sb.lineplot(\n",
    "    data=top_deaths_100K_df, \n",
    "#     kind=\"line\",\n",
    "    x=\"Date\", \n",
    "    y=\"Deaths_100K\",\n",
    "    linewidth = 4,\n",
    "    ax = ax3,\n",
    "    hue=\"Country_Region\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(frameon=False)\n",
    "plt.legend(bbox_to_anchor=(1.04,1), borderaxespad=0)\n",
    "\n",
    "ax4 = fig1.add_subplot(224)\n",
    "sb.barplot(\n",
    "    data=top_deaths_100K_df[top_deaths_100K_df['Date'] == last_reported_date], \n",
    "    x=\"IncomeGroup\", \n",
    "    y=\"Deaths_100K\",\n",
    "    ax = ax4,\n",
    "    hue=\"Country_Region\")\n",
    "plt.legend(frameon=False)\n",
    "plt.legend(bbox_to_anchor=(1.04,1), borderaxespad=0)\n",
    "\n",
    "fig1.tight_layout(pad=3)\n",
    "\n",
    "plt.savefig('Most_affected_countries.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "feeY0mPLfDvV"
   },
   "source": [
    "## Plotting the top ten LESS affected countries and Inconme level\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PbT1QbOJdMD0"
   },
   "outputs": [],
   "source": [
    "#find top 10 countries wiht highest numebr of deaths and confirmed cases (cumulative)\n",
    "my_top_n = 5\n",
    "top_deaths_100K = my_final_df.loc[last_reported_date].sort_values(by = \"Deaths_100K\", ascending = True).head(my_top_n).reset_index()['CountryCode'].to_list()#.set_index('CountryCode').to_dict()[\"Country_Region\"]\n",
    "top_confirmed_100K = my_final_df.loc[last_reported_date].sort_values(by = \"Confirmed_100K\", ascending = True).head(my_top_n).reset_index()['CountryCode'].to_list()#.set_index('CountryCode').to_dict()[\"Country_Region\"]\n",
    "\n",
    "top_deaths_100K_df = my_final_df.loc[my_final_df['CountryCode'].isin(top_deaths_100K)].reset_index()\n",
    "top_confirmed_100K_df = my_final_df.loc[my_final_df['CountryCode'].isin(top_confirmed_100K)].reset_index()\n",
    "# font = {'family' : 'normal',\n",
    "#         'weight' : 'bold',\n",
    "#         'size'   : 18}\n",
    "# plt.rc('font', **font)\n",
    "\n",
    "factor_size = 1.5\n",
    "SMALL_SIZE = 8 * factor_size\n",
    "MEDIUM_SIZE = 10 * factor_size\n",
    "BIGGER_SIZE = 12 * factor_size\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=BIGGER_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    "# Multiline Plot: number of confirmed cases in 100K \n",
    "fig1 = plt.figure(figsize=(22, 10) , dpi=300)\n",
    "\n",
    "\n",
    "ax1 = fig1.add_subplot(221)\n",
    "sb.lineplot(\n",
    "    data=top_confirmed_100K_df, \n",
    "#     kind=\"line\",\n",
    "    x=\"Date\", \n",
    "    y=\"Confirmed_100K\",\n",
    "    ax = ax1,\n",
    "    linewidth = 4,\n",
    "    hue=\"Country_Region\")\n",
    "plt.xticks(rotation=45) \n",
    "plt.legend(frameon=False)\n",
    "plt.legend(bbox_to_anchor=(1.04,1), borderaxespad=0)\n",
    "#plt.title('My title')\n",
    "\n",
    "ax2 = fig1.add_subplot(222)\n",
    "sb.barplot(\n",
    "    data=top_confirmed_100K_df[top_confirmed_100K_df['Date'] == last_reported_date], \n",
    "    x=\"IncomeGroup\", \n",
    "    y=\"Confirmed_100K\",\n",
    "    ax = ax2,\n",
    "    hue=\"Country_Region\")\n",
    "\n",
    "plt.legend(frameon=False)\n",
    "plt.legend(bbox_to_anchor=(1.04,1), borderaxespad=0)\n",
    "ax3 = fig1.add_subplot(223)\n",
    "\n",
    "sb.lineplot(\n",
    "    data=top_deaths_100K_df, \n",
    "#     kind=\"line\",\n",
    "    x=\"Date\", \n",
    "    y=\"Deaths_100K\",\n",
    "    linewidth = 4,\n",
    "    ax = ax3,\n",
    "    hue=\"Country_Region\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(frameon=False)\n",
    "plt.legend(bbox_to_anchor=(1.04,1), borderaxespad=0)\n",
    "\n",
    "ax4 = fig1.add_subplot(224)\n",
    "sb.barplot(\n",
    "    data=top_deaths_100K_df[top_deaths_100K_df['Date'] == last_reported_date], \n",
    "    x=\"IncomeGroup\", \n",
    "    y=\"Deaths_100K\",\n",
    "    ax = ax4,\n",
    "    hue=\"Country_Region\")\n",
    "plt.legend(frameon=False)\n",
    "plt.legend(bbox_to_anchor=(1.04,1), borderaxespad=0)\n",
    "\n",
    "fig1.tight_layout(pad=3)\n",
    "\n",
    "plt.savefig('Less_affected_countries.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOTE: We found that the less affected countries seem to be countries with missed information (no reported cases) or very small populated countries. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beacuse of this, we remove countries with small population size (< 1000000 people)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_top_n = 5\n",
    "best_10_confirmed=my_final_df[(my_final_df['IncomeGroup'] == 'High income') & (my_final_df['Population'] >= 1000000)].loc[last_reported_date].sort_values(by = \"Confirmed_100K\", ascending = True).head(my_top_n).reset_index()['CountryCode'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_10_deaths=my_final_df[(my_final_df['IncomeGroup'] == 'High income')& (my_final_df['Population'] >= 1000000)].loc[last_reported_date].sort_values(by = \"Deaths_100K\", ascending = True).head(my_top_n).reset_index()['CountryCode'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_deaths_100K_df = my_final_df.loc[my_final_df['CountryCode'].isin(best_10_deaths)].reset_index()\n",
    "best_confirmed_100K_df = my_final_df.loc[my_final_df['CountryCode'].isin(best_10_confirmed)].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PbT1QbOJdMD0"
   },
   "outputs": [],
   "source": [
    "#find top 10 countries wiht highest numebr of deaths and confirmed cases (cumulative)\n",
    "my_top_n = 5\n",
    "best_10_confirmed=my_final_df[(my_final_df['IncomeGroup'] == 'High income') & (my_final_df['Population'] >= 1000000)].loc[last_reported_date].sort_values(by = \"Confirmed_100K\", ascending = True).head(my_top_n).reset_index()['CountryCode'].to_list()\n",
    "best_10_deaths=my_final_df[(my_final_df['IncomeGroup'] == 'High income')& (my_final_df['Population'] >= 1000000)].loc[last_reported_date].sort_values(by = \"Deaths_100K\", ascending = True).head(my_top_n).reset_index()['CountryCode'].to_list()\n",
    "\n",
    "best_deaths_100K_df = my_final_df.loc[my_final_df['CountryCode'].isin(best_10_deaths)].reset_index()\n",
    "best_confirmed_100K_df = my_final_df.loc[my_final_df['CountryCode'].isin(best_10_confirmed)].reset_index()\n",
    "\n",
    "\n",
    "\n",
    "factor_size = 1.5\n",
    "SMALL_SIZE = 8 * factor_size\n",
    "MEDIUM_SIZE = 10 * factor_size\n",
    "BIGGER_SIZE = 12 * factor_size\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=BIGGER_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    "# Multiline Plot: number of confirmed cases in 100K \n",
    "fig1 = plt.figure(figsize=(22, 10) , dpi=300)\n",
    "\n",
    "\n",
    "ax1 = fig1.add_subplot(221)\n",
    "sb.lineplot(\n",
    "    data=best_confirmed_100K_df, \n",
    "#     kind=\"line\",\n",
    "    x=\"Date\", \n",
    "    y=\"Confirmed_100K\",\n",
    "    ax = ax1,\n",
    "    linewidth = 4,\n",
    "    hue=\"Country_Region\")\n",
    "plt.xticks(rotation=45) \n",
    "plt.legend(frameon=False)\n",
    "plt.legend(bbox_to_anchor=(1.04,1), borderaxespad=0)\n",
    "#plt.title('My title')\n",
    "\n",
    "ax2 = fig1.add_subplot(222)\n",
    "sb.barplot(\n",
    "    data=best_confirmed_100K_df[best_confirmed_100K_df['Date'] == last_reported_date], \n",
    "    x=\"IncomeGroup\", \n",
    "    y=\"Confirmed_100K\",\n",
    "    ax = ax2,\n",
    "    hue=\"Country_Region\")\n",
    "\n",
    "plt.legend(frameon=False)\n",
    "plt.legend(bbox_to_anchor=(1.04,1), borderaxespad=0)\n",
    "ax3 = fig1.add_subplot(223)\n",
    "\n",
    "sb.lineplot(\n",
    "    data=best_deaths_100K_df, \n",
    "#     kind=\"line\",\n",
    "    x=\"Date\", \n",
    "    y=\"Deaths_100K\",\n",
    "    linewidth = 4,\n",
    "    ax = ax3,\n",
    "    hue=\"Country_Region\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(frameon=False)\n",
    "plt.legend(bbox_to_anchor=(1.04,1), borderaxespad=0)\n",
    "\n",
    "ax4 = fig1.add_subplot(224)\n",
    "sb.barplot(\n",
    "    data=best_deaths_100K_df[best_deaths_100K_df['Date'] == last_reported_date], \n",
    "    x=\"IncomeGroup\", \n",
    "    y=\"Deaths_100K\",\n",
    "    ax = ax4,\n",
    "    hue=\"Country_Region\")\n",
    "plt.legend(frameon=False)\n",
    "plt.legend(bbox_to_anchor=(1.04,1), borderaxespad=0)\n",
    "\n",
    "fig1.tight_layout(pad=3)\n",
    "\n",
    "plt.savefig('Real_Less_affected_countries.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the High income countries and find out what is the best stringency index pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_final_df.IncomeGroup.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_top_n = 5\n",
    "best_10_confirmed=my_final_df[(my_final_df['IncomeGroup'] == 'High income') & (my_final_df['Population'] >= 1000000)].loc[last_reported_date].sort_values(by = \"Confirmed_100K\", ascending = True).head(my_top_n).reset_index()['CountryCode'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_10_deaths=my_final_df[(my_final_df['IncomeGroup'] == 'High income') & (my_final_df['Population'] >= 1000000)].loc[last_reported_date].sort_values(by = \"Deaths_100K\", ascending = True).head(my_top_n).reset_index()['CountryCode'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_deaths_100K_df = my_final_df.loc[my_final_df['CountryCode'].isin(best_10_deaths)].reset_index()\n",
    "best_confirmed_100K_df = my_final_df.loc[my_final_df['CountryCode'].isin(best_10_confirmed)].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PbT1QbOJdMD0"
   },
   "outputs": [],
   "source": [
    "#find top 10 countries wiht highest numebr of deaths and confirmed cases (cumulative)\n",
    "my_top_n = 5\n",
    "\n",
    "best_10_confirmed=my_final_df[(my_final_df['IncomeGroup'] == 'High income') & (my_final_df['Population'] >= 1000000)].loc[last_reported_date].sort_values(by = \"Confirmed_100K\", ascending = True).head(my_top_n).reset_index()['CountryCode'].to_list()\n",
    "best_10_deaths=my_final_df[(my_final_df['IncomeGroup'] == 'High income') & (my_final_df['Population'] >= 1000000)].loc[last_reported_date].sort_values(by = \"Deaths_100K\", ascending = True).head(my_top_n).reset_index()['CountryCode'].to_list()\n",
    "\n",
    "best_deaths_100K_df = my_final_df.loc[my_final_df['CountryCode'].isin(best_10_deaths)].reset_index()\n",
    "best_confirmed_100K_df = my_final_df.loc[my_final_df['CountryCode'].isin(best_10_confirmed)].reset_index()\n",
    "\n",
    "\n",
    "\n",
    "factor_size = 1.5\n",
    "SMALL_SIZE = 8 * factor_size\n",
    "MEDIUM_SIZE = 10 * factor_size\n",
    "BIGGER_SIZE = 12 * factor_size\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=BIGGER_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    "# Multiline Plot: number of confirmed cases in 100K \n",
    "fig1 = plt.figure(figsize=(22, 10) , dpi=300)\n",
    "\n",
    "\n",
    "ax1 = fig1.add_subplot(221)\n",
    "sb.lineplot(\n",
    "    data=best_confirmed_100K_df, \n",
    "#     kind=\"line\",\n",
    "    x=\"Date\", \n",
    "    y=\"Confirmed_100K\",\n",
    "    ax = ax1,\n",
    "    linewidth = 4,\n",
    "    hue=\"Country_Region\")\n",
    "plt.xticks(rotation=45) \n",
    "plt.legend(frameon=False)\n",
    "plt.legend(bbox_to_anchor=(1.04,1), borderaxespad=0)\n",
    "#plt.title('My title')\n",
    "\n",
    "ax2 = fig1.add_subplot(222)\n",
    "sb.lineplot(\n",
    "    data=best_confirmed_100K_df, \n",
    "#     kind=\"line\",\n",
    "    x=\"Date\", \n",
    "    y=\"StringencyIndex\",\n",
    "    ax = ax2,\n",
    "    linewidth = 4,\n",
    "    hue=\"Country_Region\")\n",
    "plt.xticks(rotation=45) \n",
    "plt.legend(frameon=False)\n",
    "plt.legend(bbox_to_anchor=(1.04,1), borderaxespad=0)\n",
    "\n",
    "ax3 = fig1.add_subplot(223)\n",
    "sb.lineplot(\n",
    "    data=best_deaths_100K_df, \n",
    "#     kind=\"line\",\n",
    "    x=\"Date\", \n",
    "    y=\"Deaths_100K\",\n",
    "    linewidth = 4,\n",
    "    ax = ax3,\n",
    "    hue=\"Country_Region\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(frameon=False)\n",
    "plt.legend(bbox_to_anchor=(1.04,1), borderaxespad=0)\n",
    "\n",
    "ax4 = fig1.add_subplot(224)\n",
    "sb.lineplot(\n",
    "    data=best_deaths_100K_df, \n",
    "#     kind=\"line\",\n",
    "    x=\"Date\", \n",
    "    y=\"StringencyIndex\",\n",
    "    ax = ax4,\n",
    "    linewidth = 4,\n",
    "    hue=\"Country_Region\")\n",
    "plt.xticks(rotation=45) \n",
    "plt.legend(frameon=False)\n",
    "plt.legend(bbox_to_anchor=(1.04,1), borderaxespad=0)\n",
    "\n",
    "fig1.tight_layout(pad=3)\n",
    "\n",
    "plt.savefig('best_perfarmance.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
