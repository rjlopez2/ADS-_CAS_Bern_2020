{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import randint\n",
    "\n",
    "import os\n",
    "from itertools import zip_longest\n",
    "from time import time\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "import umap\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.mixture import BayesianGaussianMixture\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from sklearn import preprocessing, metrics, model_selection, neural_network, linear_model, ensemble\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('data'):\n",
    "    train_df = pd.read_csv(os.path.join(os.path.abspath('.'),\n",
    "                                        \"data\", \n",
    "                                        \"train.csv\"))\n",
    "    test_df = pd.read_csv(os.path.join(os.path.abspath('.'),\n",
    "                                        \"data\", \n",
    "                                        \"test.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-14-f0127c905e5e>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34mf\"Shape of the train_df: {train_df.shape} \\nShape of the test_df: {test_df.shape}\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'train_df' is not defined"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of the train_df: {train_df.shape} \\nShape of the test_df: {test_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-18-74c44146f23a>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;31m#Capturing the columns names\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mfeatures\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlist\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain_df\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'train_df' is not defined"
     ]
    }
   ],
   "source": [
    "#Capturing the columns names\n",
    "features = list(train_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We note that labels \"id\", \"genus\" and \"species\" are present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.remove(\"id\")\n",
    "features.remove(\"genus\")\n",
    "features.remove(\"species\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.species.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(25,5))\n",
    "train_df['species'].value_counts().plot.bar(ax=ax)\n",
    "plt.title(\"Number of entries per species in the training dataset\" )\n",
    "plt.xlabel('Species')\n",
    "plt.xticks(rotation=80)\n",
    "plt.ylabel('number of records');\n",
    "plt.show\n",
    "f\"There are aparently {len(train_df.species.unique())} species in the training dataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  It looks like there are more than 20 records for species\n",
    "but closer inpection shows that in fact there are 20 records per each. We must cont the full name for a specie, that is the genus + species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['full_sp_name'] = train_df['genus'] + '_' + train_df['species']\n",
    "test_df['full_sp_name'] = test_df['genus'] + '_' + test_df['species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(25,5))\n",
    "train_df['full_sp_name'].value_counts().plot.bar(ax=ax)\n",
    "plt.title(\"Number of entries per species in the training dataset\" )\n",
    "plt.xlabel('Full qualified specie name')\n",
    "plt.xticks(rotation=80)\n",
    "plt.ylabel('number of records');\n",
    "plt.show\n",
    "print(f\"but in fact there are {len(train_df.full_sp_name.unique())} species\\nand actually 20 records per specie\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exlporing the test df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(25,5))\n",
    "test_df['full_sp_name'].value_counts().plot.bar(ax=ax)\n",
    "plt.title(\"Number of entries per species in the training dataset\" )\n",
    "plt.xlabel('Full qualified specie name')\n",
    "plt.xticks(rotation=80)\n",
    "plt.ylabel('number of records');\n",
    "plt.show\n",
    "print(f\"but in fact there are {len(test_df.full_sp_name.unique())} and diverse number of records per specie\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale/standarize dataset and encode the label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()# Declare an instance of the transformer/scaler\n",
    "scaler.fit(train_df[features])# Compute the transformation\n",
    "\n",
    "train_df[features] = pd.DataFrame(scaler.transform(train_df[features]), columns=features)# Transform (scale) the features on the train_df\n",
    "test_df[features] = pd.DataFrame(scaler.transform(test_df[features]), columns=features)# Transform (scale) the features on the test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  We take split half of the test dataframe for later validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, X_test, Y_val, Y_test = train_test_split(test_df[features], test_df['full_sp_name'], test_size=0.5, random_state=1000, stratify=test_df['full_sp_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  We will use now as:\n",
    "   1. Validation  dataset-> `x_val`, `y_val`: we will run the model and asses accuraca on the model training with this dataset.\n",
    "   2. Test dataset -> `x_test`, `y_test`: The model will never see this dataset until the end to see how perfomr with unkonw data.\n",
    "   3. And the training dataset remains is taking below from the original dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training dataset.\n",
    "x_train = train_df[features].values\n",
    "\n",
    "y_train_raw = train_df['full_sp_name'].values\n",
    "le = preprocessing.LabelEncoder()# *** Help normalize labels (numeric or in this case strings) such that they contain only values between 0 and n_classes-1\n",
    "\n",
    "y_train = le.fit_transform(y_train_raw)# Transform autput labels to numeric values.\n",
    "\n",
    "\n",
    "# Define the test and validation datasets.\n",
    "\n",
    "x_test = X_test.values\n",
    "y_raw_test = Y_test.values\n",
    "\n",
    "y_test = le.transform(y_raw_test)\n",
    "\n",
    "\n",
    "\n",
    "x_val = X_val.values\n",
    "y_val_test = Y_val.values\n",
    "\n",
    "y_val = le.transform(y_val_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"shape of train data: x_train = {x_train.shape}, y_train = {y_train.shape}\\nshape of test data: x_test = {x_test.shape}, y_test = {y_test.shape}\\nshape of val data: x_val = {x_val.shape}, y_val = {y_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use PCA to show the dataset in a reduced space dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca=PCA()\n",
    "pca.fit(x_train)\n",
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "plt.plot(pca.explained_variance_ratio_,'-o')\n",
    "plt.title('Scree plot')\n",
    "plt.ylabel('Percentage of explained variance')\n",
    "plt.xlabel('k groups')\n",
    "plt.grid()\n",
    "print('Explained variance ratio: ' ,pca.explained_variance_ratio_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding the firts two components of the PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "X_pca = pca.transform(x_train)\n",
    "plt.plot(X_pca[:,0],X_pca[:,1],'o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use umap (UMAP) to show the dataset in a reduced space dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use a helper function to visualize various parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_umap(n_neighbors=15, min_dist=0.1, \n",
    "              n_components=2, metric='euclidean', \n",
    "              title='', \n",
    "              plot_indx1 = 4, plot_indx2 = 4, plot_grid_size = 1, \n",
    "              font_s = 20,\n",
    "              scat_s = 10):\n",
    "    \n",
    "    fit = umap.UMAP(\n",
    "        n_neighbors=n_neighbors,\n",
    "        min_dist=min_dist,\n",
    "        n_components=n_components,\n",
    "        metric=metric,\n",
    "        random_state=9991\n",
    "        \n",
    "    )\n",
    "    \n",
    "    t0 = time()\n",
    "    u = fit.fit_transform(X);\n",
    "    t1 = time()\n",
    "\n",
    "    if n_components == 1:\n",
    "        ax = fig.add_subplot(plot_indx1, plot_indx2, plot_grid_size)\n",
    "        ax.scatter(u[:,0], range(len(u)))\n",
    "    if n_components == 2:\n",
    "        ax = fig.add_subplot(plot_indx1, plot_indx2, plot_grid_size)\n",
    "        ax.scatter(u[:,0], u[:,1], s=scat_s)\n",
    "    if n_components == 3:\n",
    "        ax = fig.add_subplot(plot_indx1, plot_indx2, plot_grid_size, projection='3d')\n",
    "        ax.scatter(u[:,0], u[:,1], u[:,2],  s=scat_s)\n",
    "    plt.title(title + f\"\\nelapsed time: {t1 - t0:.2f}\", fontsize=font_s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier(n_estimators=100,max_depth=50)\n",
    "forest.fit(x_train, y_train)\n",
    "forest.score(x_val, y_val)\n",
    "print(\"Accuracy on training set: {:.3f}\".format(forest.score(x_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(forest.score(x_val, y_test)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "poly.fit(x_train)\n",
    "X_train_poly = poly.transform(x_train)\n",
    "X_val_poly = poly.transform(x_val)\n",
    "\n",
    "print(\"X_train.shape: {}\".format(x_train.shape))\n",
    "print(\"X_train_poly.shape: {}\".format(X_train_poly.shape))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Extending the number of feautures by using polynomialfeatures function in order to incraese accuracy of the model\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge = Ridge().fit(x_train, y_train)\n",
    "print(\"Training set score: {:.2f}\".format(ridge.score(x_train, y_train)))\n",
    "print(\"Test set score: {:.2f}\".format(ridge.score(X_val, y_val)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ridge = Ridge().fit(x_train, y_train)\n",
    "print(\"Score without interactions: {:.3f}\".format(\n",
    "    ridge.score(x_val, y_val)))\n",
    "ridge = Ridge().fit(X_train_poly, y_train)\n",
    "print(\"Score with interactions: {:.3f}\".format(ridge.score(X_val_poly, y_val)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Polinomial feautures have significanlty increased the performance of the model\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler().fit(x_train)\n",
    "X_train_scaled = scaler.transform(x_train)\n",
    "LinearSVC = LinearSVC(C=100)\n",
    "LinearSVC.fit(x_train, y_train)\n",
    "LinearSVC.score(X_val, y_val)\n",
    "print(\"Training set score: {:.3f}\".format(LinearSVC.score(x_train, y_train)))\n",
    "print(\"Test set score: {:.3f}\".format(LinearSVC.score(x_val, y_val)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "logreg = LogisticRegression().fit(x_train, y_train)\n",
    "print(\"Training set score: {:.3f}\".format(logreg.score(x_train, y_train)))\n",
    "print(\"Test set score: {:.3f}\".format(logreg.score(X_val, y_val)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'logreg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-1-463dfb164281>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0msklearn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msvm\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mSVC\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mpred_logreg\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlogreg\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX_val\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m \u001B[0mconfusion\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mconfusion_matrix\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my_val\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpred_logreg\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"Confusion matrix:\\n{}\"\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mconfusion\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[0mprint\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mclassification_report\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my_val\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0msvc\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx_test\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'logreg' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "pred_logreg = logreg.predict(X_val)\n",
    "confusion = confusion_matrix(y_val, pred_logreg)\n",
    "print(\"Confusion matrix:\\n{}\".format(confusion))\n",
    "print (classification_report(y_val,svc.predict(x_test)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 1.000\n",
      "Test set score: 0.979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valer\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "logreg100 = LogisticRegression(C=100)\n",
    "logreg100.fit(x_train, y_train)\n",
    "print(\"Training set score: {:.3f}\".format(logreg100.score(x_train, y_train)))\n",
    "print(\"Test set score: {:.3f}\".format(logreg100.score(X_val, y_val)))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%The performance of logistic regression increased significantly with the number of itirations\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'confusion' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-16-8f6455c61028>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 8\u001B[1;33m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"Confusion matrix:\\n{}\"\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mconfusion\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      9\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     10\u001B[0m \u001B[0msvc\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mSVC\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mgamma\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m.05\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'confusion' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import preprocessing, metrics, model_selection, neural_network, linear_model, ensemble\n",
    "\n",
    "\n",
    "print(\"Confusion matrix:\\n{}\".format(confusion))\n",
    "\n",
    "svc = SVC(gamma=.05).fit(x_train, y_train)\n",
    "print(classification_report(y_val, svc.predict(x_val)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring different neighbors and minimal distance (hyperparameter landscape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extractting 2 components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run me only locally\n",
    "components = 2\n",
    "neigbords = [5, 10, 50, 100, 200]\n",
    "distance = [0.1, 0.25, 0.5, 0.8, 0.99]\n",
    "\n",
    "fig_Count = 0\n",
    "nrows, ncols = len(neigbords), len(distance)\n",
    "\n",
    "fig = plt.figure(figsize=(60, 60))\n",
    "\n",
    "for indx1, n  in enumerate(neigbords, start=1):\n",
    "    for indx2, d in enumerate(distance, start=1):\n",
    "        fig_Count += 1\n",
    "#         print(f\"this is my neigb: {i} and this is my distance {j} and index1: {indx1} and index2: {indx2}\")\n",
    "        draw_umap(min_dist=d, \n",
    "                     n_neighbors=n,\n",
    "                     n_components= components, \n",
    "                     title=f'min_dist = {d} and neigbords {n}',\n",
    "                     plot_indx1 = nrows, plot_indx2 = ncols, plot_grid_size = fig_Count)\n",
    "\n",
    "fig.tight_layout(pad=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use TSNE to show the dataset in a reduced space dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use a helper function to visualize various parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_TSNE(n_perplex=125, \n",
    "              learn_rate=200, \n",
    "              early_exag=4.0,\n",
    "              init='pca',\n",
    "              n_itera=1000, \n",
    "              metric='euclidean', \n",
    "              verbo=100,\n",
    "              title='', \n",
    "              plot_indx1 = 4, plot_indx2 = 4, plot_grid_size = 1, \n",
    "              font_s = 20,\n",
    "              scat_s = 10):\n",
    "    \n",
    "    \n",
    "    fit = TSNE(perplexity=n_perplex, \n",
    "               learning_rate=learn_rate, \n",
    "               early_exaggeration=early_exag,\n",
    "               init=init,\n",
    "               n_iter=n_itera, \n",
    "               random_state=9999991, \n",
    "               metric=metric, \n",
    "               verbose=0 )\n",
    "    \n",
    "    t0 = time()\n",
    "    u = fit.fit_transform(X);\n",
    "    t1 = time()\n",
    "\n",
    "    ax = fig.add_subplot(plot_indx1, plot_indx2, plot_grid_size)\n",
    "    ax.scatter(u[:,0], u[:,1], s=scat_s)\n",
    "    \n",
    "    plt.title(title + f\"\\nelapsed time: {t1 - t0:.2f}\", fontsize=font_s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run me only locally\n",
    "\n",
    "learning_rate=200\n",
    "itera=500\n",
    "\n",
    "perplexity=[10, 50, 100]\n",
    "exagg=[1, 5.0, 10.0]\n",
    "\n",
    "\n",
    "\n",
    "fig_Count = 0\n",
    "nrows, ncols = len(perplexity), len(exagg)\n",
    "\n",
    "fig = plt.figure(figsize=(40, 40))\n",
    "\n",
    "for indx1, p  in enumerate(perplexity, start=1):\n",
    "    for indx2, e in enumerate(exagg, start=1):\n",
    "        fig_Count += 1\n",
    "#         print(f\"this is my neigb: {i} and this is my distance {j} and index1: {indx1} and index2: {indx2}\")\n",
    "        draw_TSNE(n_perplex=p, \n",
    "                  learn_rate=learning_rate, \n",
    "                  early_exag=e,\n",
    "                  n_itera=itera,\n",
    "                  title=f'Early_exaggeration = {e}\\nperpelexity = {p}',\n",
    "                  plot_indx1 = nrows, plot_indx2 = ncols, plot_grid_size = fig_Count,\n",
    "                  font_s = 20, scat_s = 20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the numbers of clusters via K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run me only locally\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "scores=[]\n",
    "clusters = 500\n",
    "\n",
    "\n",
    "for itrial in range(2,clusters):\n",
    "#     print('Number of clusters considered: ',itrial)\n",
    "    clusterer = KMeans(n_clusters=itrial, random_state=10)\n",
    "    cluster_labels = clusterer.fit_predict(X)\n",
    "    score=silhouette_score(X,cluster_labels)\n",
    "    scores.append(score)\n",
    "    \n",
    "plt.grid()\n",
    "plt.plot(np.arange(len(scores))+2,np.array(scores),'-o')\n",
    "plt.ylabel('Silohuette score');\n",
    "plt.xlabel('number of clusters');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assesing Gaussian mixture for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # No need to run this code\n",
    "# n_rows, n_cols = list(range(1, 5)), list(range(1, 5))\n",
    "# start, end = 80, 96\n",
    "\n",
    "# aic=[]\n",
    "# bic=[]\n",
    "# sil=[]\n",
    "\n",
    "# scat_s = 20\n",
    "# font_s = 20\n",
    "# fig = plt.figure(figsize=(60, 60))\n",
    "\n",
    "# for indx, i_comp in enumerate(range(start, end), start = 1):\n",
    "#     ax = fig.add_subplot(len(n_rows), len(n_cols), indx)\n",
    "    \n",
    "#     clf =  GaussianMixture(n_components=i_comp, covariance_type='full')\n",
    "    \n",
    "    \n",
    "# #     u = clf.fit_transform(X);\n",
    "    \n",
    "#     t0 = time()\n",
    "#     clf.fit(X)\n",
    "#     cluster_labels=clf.predict(X)\n",
    "#     t1 = time()\n",
    "    \n",
    "#     ax.scatter(X[:,0], X[:,1], c = cluster_labels, s = scat_s)\n",
    "#     plt.title(f\"components: {i_comp}\\nelapsed time :{t1 - t0:.2f}\\nIC: {clf.aic(X):.2f}\\nBIC: {clf.bic(X):.2f}\\nSilhouette_score: {silhouette_score(X,cluster_labels):.2f}\", fontsize = font_s)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(20, 10))\n",
    "# scat_s = 20\n",
    "# font_s = 20\n",
    "# i_comp = 85\n",
    "    \n",
    "# clf =  GaussianMixture(n_components=i_comp, covariance_type='full')\n",
    "    \n",
    "    \n",
    "# # u = clf.fit_transform(X);\n",
    "    \n",
    "# t0 = time()\n",
    "# clf.fit(X)\n",
    "# cluster_labels=clf.predict(X)\n",
    "# t1 = time()\n",
    "\n",
    "\n",
    "# plt.scatter(X[:,0], X[:,1], c = cluster_labels, s = scat_s)\n",
    "# plt.title(f\"components: {i_comp}\\nelapsed time :{t1 - t0:.2f}\\nIC: {clf.aic(X):.2f}\\nBIC: {clf.bic(X):.2f}\\nSilhouette_score: {silhouette_score(X,cluster_labels):.2f}\", fontsize = font_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the Gaussian mixture performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "scat_s = 20\n",
    "font_s = 20\n",
    "\n",
    "n_components = np.arange(2, 100, 1)\n",
    "models = [GaussianMixture(n, covariance_type='full', random_state=0).fit(X)\n",
    "          for n in n_components]\n",
    "\n",
    "plt.plot(n_components, [m.bic(X) for m in models], label='Bayesian information criterion (BIC)')\n",
    "plt.plot(n_components, [m.aic(X) for m in models], label='Akaike information criterion (AIC)')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('n_components', fontsize = font_s);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and compare 3 models:\n",
    "1. logisteic regression, \n",
    "2. Random Forest\n",
    "3. Forward neural network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()# Declare an instance of the transformer/scaler\n",
    "scaler.fit(train_df[features])# Compute the transformation\n",
    "\n",
    "train_df[features] = pd.DataFrame(scaler.transform(train_df[features]), columns=features)# Transform (scale) the features on the train_df\n",
    "test_df[features] = pd.DataFrame(scaler.transform(test_df[features]), columns=features)# Transform (scale) the features on the test_df\n",
    "\n",
    "X = train_df[features].values\n",
    "y_raw = train_df['full_sp_name'].values\n",
    "\n",
    "le = preprocessing.LabelEncoder()# *** Help normalize labels (numeric or in this case strings) such that they contain only values between 0 and n_classes-1\n",
    "\n",
    "y = le.fit_transform(y_raw)# Transform autput labels to numeric values.\n",
    "\n",
    "X_test = test_df[features].values\n",
    "y_raw_test = test_df['full_sp_name'].values\n",
    "\n",
    "y_test = le.transform(y_raw_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we can see there are very noticeable clusters let's see if some model can learn to distinguish between the species\n",
    "\n",
    "sss = model_selection.StratifiedShuffleSplit(n_splits=5,test_size=0.2)\n",
    "\n",
    "log_reg_accs = []\n",
    "log_reg_ap = []\n",
    "log_reg_f1 = []\n",
    "log_reg_preds = np.zeros((5,len(X_test)))\n",
    "\n",
    "rand_forest_accs = []\n",
    "rand_forest_ap = []\n",
    "rand_forest_f1 = []\n",
    "rand_forest_preds = np.zeros((5,len(X_test)))\n",
    "\n",
    "nn_accs = []\n",
    "nn_ap = []\n",
    "nn_f1 = []\n",
    "nn_preds = np.zeros((5,len(X_test)))\n",
    "\n",
    "i = 0\n",
    "\n",
    "for train_index, val_index in sss.split(X, y):\n",
    "    X_train, X_val = X[train_index], X[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "    \n",
    "    log_reg = linear_model.LogisticRegression(solver='lbfgs', multi_class='auto')\n",
    "    log_reg.fit(X_train, y_train)\n",
    "    y_val_pred = log_reg.predict(X_val)\n",
    "    log_reg_accs.append(metrics.accuracy_score(y_val_pred, y_val))\n",
    "    log_reg_preds[i] = log_reg.predict(X_test)\n",
    "    \n",
    "    rand_forest = ensemble.RandomForestClassifier(n_estimators=100)\n",
    "    rand_forest.fit(X_train, y_train)\n",
    "    y_val_pred = rand_forest.predict(X_val)\n",
    "    rand_forest_accs.append(metrics.accuracy_score(y_val_pred, y_val))\n",
    "    rand_forest_preds[i] = rand_forest.predict(X_test)\n",
    "    \n",
    "    \n",
    "    nn = neural_network.MLPClassifier(activation='relu',hidden_layer_sizes=[128,128])\n",
    "    nn.fit(X_train, y_train)\n",
    "    y_val_pred = nn.predict(X_val)\n",
    "    nn_accs.append(metrics.accuracy_score(y_val_pred, y_val))\n",
    "    nn_preds[i] = nn.predict(X_test)\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "print(\"Accuracy of Logistic Regression on validation set: \", np.mean(log_reg_accs))\n",
    "print(\"Accuracy of Random Forest on validation set: \", np.mean(rand_forest_accs))\n",
    "print(\"Accuracy of Feed Forward Neural Network on validation set: \", np.mean(nn_accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a neural network with tensor flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5, 20):\n",
    "    print(2**i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_bird_song_model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Dense(2048, activation='relu', name=\"layer1\", input_shape=(169,)),\n",
    "#     tf.keras.layers.Dense(2048, activation='relu', name=\"layer3\"),\n",
    "#     tf.keras.layers.Dense(4096, activation='relu', name=\"layer4\"),\n",
    "#     tf.keras.layers.Dense(1024, activation='relu', name=\"layer5\"),\n",
    "#     tf.keras.layers.Dense(512, activation='relu', name=\"layer6\"),\n",
    "#     tf.keras.layers.Dense(256, activation='relu', name=\"layer7\"),\n",
    "    tf.keras.layers.Dense(88, activation='softmax', name=\"layer8\")\n",
    "    ])\n",
    "\n",
    "my_bird_song_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_bird_song_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = 'save/nn_model_bird_class_{epoch}.ckpt'\n",
    "save_callback = tf.keras.callbacks.ModelCheckpoint(filepath=save_path, save_weights_only=True)\n",
    "\n",
    "hist = my_bird_song_model.fit(x_train, y_train,\n",
    "                              epochs=20, batch_size=150, \n",
    "                              validation_data=(x_val, y_val),#this has to be a tupple () not a list [] \n",
    "                              callbacks=[save_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(20,10))\n",
    "axs[0].plot(hist.epoch, hist.history['loss'])\n",
    "axs[0].plot(hist.epoch, hist.history['val_loss'])\n",
    "axs[0].legend(('training loss', 'validation loss'), loc='upper right')\n",
    "axs[1].plot(hist.epoch, hist.history['accuracy'])\n",
    "axs[1].plot(hist.epoch, hist.history['val_accuracy'])\n",
    "\n",
    "axs[1].legend(('training accuracy', 'validation accuracy'), loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_classes_dic = {}\n",
    "for n, i in enumerate(le.classes_, start = 0):\n",
    "    print(n, i )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pick a random entry from the unseen test dataset and make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"shape of train data: x_train = {x_train.shape}, y_train = {y_train.shape}\\nshape of test data: x_test = {x_test.shape}, y_test = {y_test.shape}\\nshape of val data: x_val = {x_val.shape}, y_val = {y_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_test_value = randint(0, 8313)\n",
    "print(f\"The random entry is {my_test_value}\\nand correspond to {le.inverse_transform([y_test[my_test_value]])[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_prediction = my_bird_song_model.predict(x_test[[my_test_value], :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "May be define a function that return the 3 hits with the highest probabilities?...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, i in enumerate(my_prediction[0], start=0):\n",
    "    print(n, round(i, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "name": "pycharm-fcbb258b",
   "language": "python",
   "display_name": "PyCharm (Birds New Project)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}